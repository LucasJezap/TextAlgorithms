{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytmy Tekstowe 2019/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor - Łukasz Jezapkowicz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym punkcie wczytam pliki załączone do zadania. Są to odpowiednio pliki '1997_714.txt', 'romeo-i-julia-700.txt' oraz 'zad6'.  \n",
    "  \n",
    "W całym Notebooku dostępne będą one pod (odpowiednio) nazwami 'data1', 'data2' oraz 'data3'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otwieranie pliku\n",
    "def open_file(file):\n",
    "    file = open(file,mode='r', encoding=\"utf-8\")\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = open_file('1997_714.txt')\n",
    "data2 = open_file('romeo-i-julia-700.txt')\n",
    "data3 = open_file('zad6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Dz.U. z 1998 r. Nr 144, poz. 930\n",
      "                                       \n",
      "                                       \n",
      "                                       \n",
      "                                       \n",
      "                                    USTAWA\n",
      "                          z dnia 20 listopada 1998 r.\n",
      "                                       \n",
      "         o zryczałtowanym podatku dochodowym od niektórych przychodów\n",
      "                        osiąganych przez osoby fizyczne\n",
      "                                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data1[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "William Shakespeare\n",
      "\n",
      "Romeo i Julia\n",
      "tłum. Józef Paszkowski\n",
      "\n",
      "ISBN 978-83-288-2903-9\n",
      "\n",
      "\n",
      "\n",
      "OSOBY:\n",
      " * ESKALUS — książę panujący w Weronie\n",
      " * PARYS — młody Weroneńczyk szlachetnego rodu, krewny księcia\n",
      " * MONTEKI, KAPULET — naczelnicy dwóch domów nieprzyjaznych sobie\n",
      " * STARZEC — stryjeczny brat Kapuleta\n",
      " * ROMEO — syn Montekiego\n",
      " * MERKUCJO — krewny księcia\n",
      " * BENWOLIO — synowiec Montekiego\n",
      " * TYBALT — krewny Pani Kapulet\n",
      " * LAURENTY — ojciec franciszkanin\n",
      " * JAN — brat z tegoż zgromadzenia\n",
      " * BALTAZAR\n"
     ]
    }
   ],
   "source": [
    "print(data2[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Zaimplementować budowę słownika podstawowych składowych.\n",
      "2. Zaimplementować wyszukiwanie wzorca korzystając z DBF. Wyszukiwanie ma działać dla każdej długości wzorca nie większej od długości całego tekstu. Czy konieczne jest budowanie nowego DBF dla pat&text?\n",
      "3. Sprawdzić rzeczywisty czas budowy DBF dla załączonych plików. Porównać z czasem budowy drzewa sufiksów.*\n",
      "4. Zbadać rzeczywisty rozmiar DBF, porównać z wielkością pliku.\n",
      "5. Porównać czas wyszukiwania wzorca przy użyciu DBF z wyszukiwaniem za pomocą KMP dla różnych długości wzorca.**\n",
      "\n",
      "* Osoby, które nie zaimplementowały drzewa sufiksów w poprzednich zadaniach mogą skorzystać np. z tej implementacji (w Pythonie): https://github.com/kvh/Python-Suffix-Tree\n",
      "** j.w. dla algorytmu KMP: https://www.geeksforgeeks.org/kmp-algorithm-for-pattern-searching/\n",
      "\n",
      "Rozwiązanie powinno zawierać kod oraz sprawozdanie w formacie PDF lub Jupyter Notebook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Zaimplementować budowę słownika podstawowych składowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W poniższej implementacji stosuje symbolikę taką jak na wykładzie 5. Za słownik podstawowych składowych przyjmuję tablice Name oraz Pos dla wartości k będących potęgami liczby 2 nie większymi od długości tekstu w.  \n",
    "  \n",
    "W tym celu na początku zaimplementuję funkcję sort_rename, której zadaniem jest wyliczenie uporządkowanego etykietowania dla wejściowego ciągu S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zwracająca pierwszy element krotki\n",
    "def extract_key(el):\n",
    "    return el[0]\n",
    "\n",
    "# funkcja wyliczająca uporządkowane etykietowanie dla ciągu wejściowego S\n",
    "# funkcja zwraca znalezione etykietowanie\n",
    "def sort_rename(S):\n",
    "    # dodawanie indeksów\n",
    "    for i in range(1,len(S)+1):\n",
    "        S[i-1] = (S[i-1],i)\n",
    "    \n",
    "    # sortowanie leksykograficzne\n",
    "    S.sort()\n",
    "    \n",
    "    grouped = [[k,[x[1] for x in g]] for k, g in itertools.groupby(S, extract_key)]\n",
    "    \n",
    "    pos = []\n",
    "    name = [None] * len(S)\n",
    "    i = 1\n",
    "    for element in grouped:\n",
    "        pos.append(element[1])\n",
    "        for index in element[1]:\n",
    "            name[index-1] = i\n",
    "        i += 1\n",
    "            \n",
    "    return name, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dla przykładowych danych (identycznych jak na wykładzie). Przyjąłem indeksowanie od 1. Warto zauważyć, że w tablicy $Pos$ przechowuje wszystkie indeksy dla danego fragmentu (co przyda mi się w późniejszym czasie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: [2, 5, 3, 1, 4, 2]\n",
      "Pos: [[4], [1, 6], [3], [5], [2]]\n"
     ]
    }
   ],
   "source": [
    "X = [(1,2),(3,1),(2,2),(1,1),(2,3),(1,2)]\n",
    "name, pos = sort_rename(X)\n",
    "print('Name: ' + str(name))\n",
    "print('Pos: ' + str(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie zaimplementuję algorytm KMR, którego działanie opiera się na następującym fakcie:  \n",
    "  \n",
    "$Name_{2k}=sort\\_rename(composite\\_name_k)$  \n",
    "  \n",
    "$composite\\_name_k[i]=(Name_k[i],Name_k[i+k])$  \n",
    "  \n",
    "Czyli możemy łatwo obliczać tablice Name i Pos dla kolejnych potęg 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja realizująca algorytm KMR\n",
    "def kmr(text):\n",
    "    # kolejne tablice przechowywane w słowniku\n",
    "    orig_length = len(text)\n",
    "    names = dict()\n",
    "    positions = dict()\n",
    "    \n",
    "    # dodawanie znaków # do tekstu\n",
    "    factor = math.floor(math.log2(len(text)))\n",
    "    text += '~' * (2 ** (factor+1) - 1)\n",
    "    \n",
    "    # tablice name i pos dla k = 1\n",
    "    name, pos = sort_rename(list(text))\n",
    "    names[1] = name[:orig_length]\n",
    "    positions[1] = pos[:-1]\n",
    "    \n",
    "    # kolejne potęgi 2\n",
    "    for i in range(1,factor+1):\n",
    "        k = 2 ** i\n",
    "        seq = []\n",
    "        tmp = 2 ** (i-1)\n",
    "        for j in range(orig_length):\n",
    "            if (j + tmp < len(names[tmp])):\n",
    "                seq.append((names[tmp][j],names[tmp][j+tmp]))\n",
    "            else:\n",
    "                seq.append((names[tmp][j],ord('~')))\n",
    "\n",
    "        name, pos = sort_rename(seq)\n",
    "        names[k] = name\n",
    "        positions[k] = pos\n",
    "                \n",
    "    return names, positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład działania (z wykładu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "1 [1, 2, 2, 1, 2, 2, 1, 2, 1]\n",
      "2 [1, 4, 3, 1, 4, 3, 1, 3, 2]\n",
      "4 [2, 7, 5, 2, 7, 4, 1, 6, 3]\n",
      "8 [3, 9, 6, 2, 8, 5, 1, 7, 4]\n",
      "\n",
      "positions:\n",
      "1 [[1, 4, 7, 9], [2, 3, 5, 6, 8]]\n",
      "2 [[1, 4, 7], [9], [3, 6, 8], [2, 5]]\n",
      "4 [[7], [1, 4], [9], [6], [3], [8], [2, 5]]\n",
      "8 [[7], [4], [1], [9], [6], [3], [8], [5], [2]]\n"
     ]
    }
   ],
   "source": [
    "names, positions = kmr(\"abbabbaba\")\n",
    "\n",
    "print(\"names:\")\n",
    "for k,v in names.items():\n",
    "    print(k,v)\n",
    "\n",
    "print(\"\\npositions:\")\n",
    "for k,v in positions.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Zaimplementować wyszukiwanie wzorca korzystając z DBF. Wyszukiwanie ma działać dla każdej długości wzorca nie większej od długości całego tekstu. Czy konieczne jest budowanie nowego DBF dla pat&text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początku zaimplementuję wersje algorytmu, który buduje DBF dla pat&text.  \n",
    "  \n",
    "Dla długości wzorca nie będącej potęgą dwójki możemy skorzystać z poniższej zalezności:  \n",
    "  \n",
    "$ Name_q[i]=Name_q[j] <=> (Name_t[i]=Name_t[j]\\; and\\; Name_t[i+q-t]=Name_t[j+q-t])$  \n",
    "  \n",
    "gdzie t jest największą potegą 2 mniejszą od długości wzorca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# funkcja implementująca wyszukiwanie wzorca korzystając z DBF\n",
    "def pattern_dbf(text,pattern,print_results = True):\n",
    "    if len(pattern) > len(text):\n",
    "        print(\"Pattern is longer than text!\")\n",
    "        return\n",
    "    time1 = time()\n",
    "    names, positions = kmr(pattern + '&' + text)\n",
    "    \n",
    "    count = 0\n",
    "    # długość wzorca to potęga 2\n",
    "    if len(pattern) in names != None:\n",
    "        name = names[len(pattern)]\n",
    "        pat_lab = name[0]\n",
    "        \n",
    "        # omijam niepotrzebne elementy (pattern + &)\n",
    "        for i in range(len(pattern)+1,len(name)):\n",
    "            if name[i] == pat_lab:\n",
    "                if print_results:\n",
    "                    print(\"Pattern found starting at index \" + str(i-len(pattern)-1))\n",
    "                count += 1\n",
    "    else:\n",
    "        # największa składowa mniejsza od len(pattern) będąca potęgą 2\n",
    "        smaller_factor = math.floor(math.log2(len(pattern)))\n",
    "        k = 2 ** smaller_factor\n",
    "        name = names[k]\n",
    "        diff = len(pattern)-k\n",
    "        \n",
    "        # omijam niepotrzebne elementy i korzystam z powyższej zależności\n",
    "        for i in range(len(pattern)+1,len(name)):\n",
    "            if name[0] == name[i] and name[diff] == name[i + diff]:\n",
    "                if print_results:\n",
    "                    print(\"Pattern found starting at index \" + str(i-len(pattern)-1))\n",
    "                count += 1\n",
    "        \n",
    "    print(\"Total number of patterns found : \" + str(count))\n",
    "    if not print_results:\n",
    "        print('It took ' + str(time()-time1) + ' seconds to find all occurences of given pattern in given text.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykład działania poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 6\n",
      "Pattern found starting at index 9\n",
      "Pattern found starting at index 11\n",
      "Total number of patterns found : 6\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego pojedynczym symbolem (spodziewamy się 6 liter a)\n",
    "pattern_dbf(\"ababababbaba\",\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 6\n",
      "Pattern found starting at index 9\n",
      "Total number of patterns found : 5\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego potęgą 2 (spodziewamy się 5 wystąpień ab)\n",
    "pattern_dbf(\"ababababbaba\",\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 9\n",
      "Total number of patterns found : 4\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca nie będącego potęga 2 (spodziewamy się 4 wystąpień aba)\n",
    "pattern_dbf(\"ababababbaba\",\"aba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Total number of patterns found : 1\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego tekstem (spodziewamy się 1 wystąpienia)\n",
    "pattern_dbf(\"ababababbaba\",\"ababababbaba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern is longer than text!\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca dłuższego niż tekst (nie powinniśmy niczego szukać)\n",
    "pattern_dbf(\"ababababbaba\",\"ababababbabaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy można bez pattern&text?\n",
    "  \n",
    "Warto zauważyć, że w powyższej implementacji w ogóle nie korzystamy z tablicy $Pos$. Można więc sądzić, że nie wykorzystujemy całości informacji dostarczonych przez $KMR$.  \n",
    "  \n",
    "Poszczególne tablice $Pos[i]$ zawierają numery indeksów rozpoczynających kolejne fragmenty (tablica jest uporządkowana leksykograficznie względem fragmentów - kluczowa informacja!).  \n",
    "  \n",
    "Moglibyśmy zatem dla wzorca o długości $k$ wziąć pod uwagę tablicę $Pos[i]$, gdzie $i\\;=\\;max\\;\\{j\\;:2^j\\;<= k\\}$ (czyli najdłuższy możliwy prefiks naszego wzorca). W owej tablicy moglibyśmy użyć wyszukiwania binarnego w celu znalezienia czy istnieją wystąpienia naszego wzorca (tablica jest uporządkowana). Zależnie od tego czy k jest potęgą dwójki algorytm dzieliłby się na dwie metodyki:\n",
    "  \n",
    "- jeśli jest, to porównujemy cały wzorzec z każdym fragmentem zaczynającym się w danym fragmencie. Jeśli znajdziemy listę indeksów, w której pierwszy element pasuje to cała lista jest szukanym rozwiązaniem.\n",
    "  \n",
    "- jeśli nie jest, to porównujemy tylko fragmenty o długości $i$ i jeżeli znajdziemy listę, w której porównanie zakończyło się pozytywnie, to sprawdzamy każdy jej element tak jak w poprzedniej metodzie (dla przykładu, szukając wzorca $abb$ i biorąc listę $[ab,ab,ab]$ i odpowiadające jej fragmenty $[aba,abb,abb]$ moglibyśmy odrzucić pasujące rozwiązania gdybyśmy postępowali jak powyżej).\n",
    "  \n",
    "Złożoność takiego rozwiązania (nie przyjmując żadnych pesymistycznych sytuacji, wyjdzie w praniu) to $O(k*logn)$. Jak widać jest to dosyć obiecująca złożoność, zobaczymy jak wyjdą wyniki.\n",
    "  \n",
    "Poniżej znajduje się implementacja wyżej wymienionego pomysłu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja porównująca dwa fragmenty tekstu (leksykograficznie)\n",
    "def compare_chunks(chunk1, chunk2, length):\n",
    "    if len(chunk1) < length:\n",
    "        chunk1 += '~' * (length - len(chunk1))\n",
    "        \n",
    "    t1 = chunk1[:length]\n",
    "    t2 = chunk2[:length]\n",
    "    if t1 > t2:\n",
    "        return 1\n",
    "    elif t1 < t2:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zwracająca szukaną listę lub None, gdy takiej nie ma\n",
    "def find_list(positions, text, pattern, length):\n",
    "    i = 2 ** (math.floor(math.log2(length))) # szukany indeks\n",
    "    l, r, mid = 0, len(positions[i]) - 1, length / 2\n",
    "    pos = positions[i]\n",
    "    while l <= r: \n",
    "        mid = (l + r) // 2\n",
    "        cur_pos = pos[mid][0]-1\n",
    "        comp = compare_chunks(text[cur_pos:(cur_pos+length)],pattern,length)\n",
    "        if comp == 1:\n",
    "            r = mid - 1\n",
    "        elif comp == -1:\n",
    "            l = mid + 1\n",
    "        else:\n",
    "            return pos[mid]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja znajdująca wzorzec przy pomocy gotowego DBF\n",
    "def better_pattern_dbf(dbf,text,pattern,print_results=True):\n",
    "    if len(pattern) > len(text):\n",
    "        print(\"Pattern is longer than text!\")\n",
    "        return\n",
    "    time1 = time()\n",
    "    # najpierw poszukujemy naszej listy\n",
    "    indexes_list = find_list(dbf[1],text,pattern,len(pattern))\n",
    "    \n",
    "    if indexes_list is not None:\n",
    "        if len(pattern) == 2 ** (math.floor(math.log2(len(pattern)))): # jest potęgą 2\n",
    "            for index in indexes_list:\n",
    "                if print_results:\n",
    "                    print(\"Pattern found starting at index \" + str(index-1))\n",
    "            print(\"Total number of patterns found : \" + str(len(indexes_list)))\n",
    "        else:\n",
    "            count = 0\n",
    "            for index in indexes_list:\n",
    "                if pattern == text[index-1:index-1+len(pattern)]:\n",
    "                    if print_results:\n",
    "                        print(\"Pattern found starting at index \" + str(index-1))\n",
    "                    count += 1\n",
    "            print(\"Total number of patterns found : \" + str(count))\n",
    "    if not print_results:\n",
    "        print('It took ' + str(time()-time1) + ' seconds to find all occurences of given pattern in given text.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestujmy teraz działanie naszego algorytmu (narazie bez mierzenia czasów)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ababababbaba\"\n",
    "dbf = kmr(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 6\n",
      "Pattern found starting at index 9\n",
      "Pattern found starting at index 11\n",
      "Total number of patterns found : 6\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego pojedynczym symbolem (spodziewamy się 6 liter a)\n",
    "better_pattern_dbf(dbf,text,\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 6\n",
      "Pattern found starting at index 9\n",
      "Total number of patterns found : 5\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego potęgą 2 (spodziewamy się 5 wystąpień ab)\n",
    "better_pattern_dbf(dbf,text,\"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Pattern found starting at index 2\n",
      "Pattern found starting at index 4\n",
      "Pattern found starting at index 9\n",
      "Total number of patterns found : 4\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca nie będącego potęga 2 (spodziewamy się 4 wystąpień aba)\n",
    "better_pattern_dbf(dbf,text,\"aba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found starting at index 0\n",
      "Total number of patterns found : 1\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca będącego tekstem (spodziewamy się 1 wystąpienia)\n",
    "better_pattern_dbf(dbf,text,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern is longer than text!\n"
     ]
    }
   ],
   "source": [
    "# wyszukiwanie wzorca dłuższego niż tekst (nie powinniśmy niczego szukać)\n",
    "better_pattern_dbf(dbf,text,\"ababababbabaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać wyniki są identyczne jak dla wersji z budowaniem nowego $DBF$. Algorytm działa zatem poprawnie. To jak algorytm spisuje się czasowo przetestujemy później."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sprawdzić rzeczywisty czas budowy DBF dla załączonych plików (3 pliki). Porównać z czasem budowy drzewa sufiksów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej wersja KMR z dodanym mierzeniem czasu (jedyna zmiana w kodzie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja realizująca algorytm KMR oraz zliczająca czas budowy\n",
    "def kmr_time(text):\n",
    "    time1 = time()\n",
    "    # kolejne tablice przechowywane w słowniku\n",
    "    orig_length = len(text)\n",
    "    names = dict()\n",
    "    positions = dict()\n",
    "    \n",
    "    # dodawanie znaków # do tekstu\n",
    "    factor = math.floor(math.log2(len(text)))\n",
    "    text += '~' * (2 ** (factor+1) - 1)\n",
    "    \n",
    "    # tablice name i pos dla k = 1\n",
    "    name, pos = sort_rename(list(text))\n",
    "    names[1] = name[:orig_length]\n",
    "    positions[1] = pos[:-1]\n",
    "    \n",
    "    # kolejne potęgi 2\n",
    "    for i in range(1,factor+1):\n",
    "        k = 2 ** i\n",
    "        seq = []\n",
    "        tmp = 2 ** (i-1)\n",
    "        for j in range(orig_length):\n",
    "            if (j + tmp < len(names[tmp])):\n",
    "                seq.append((names[tmp][j],names[tmp][j+tmp]))\n",
    "            else:\n",
    "                seq.append((names[tmp][j],ord('~')))\n",
    "\n",
    "        name, pos = sort_rename(seq)\n",
    "        names[k] = name\n",
    "        positions[k] = pos\n",
    "    \n",
    "    print('It took ' + str(time()-time1) + ' seconds to build DBF from given text.')\n",
    "    return names, positions, time()-time1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej czas budowania DBF dla kolejnych plików."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_dbf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 25.63781499862671 seconds to build DBF from given text.\n"
     ]
    }
   ],
   "source": [
    "times_dbf.append(kmr_time(data1)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.599107027053833 seconds to build DBF from given text.\n"
     ]
    }
   ],
   "source": [
    "times_dbf.append(kmr_time(data2)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.024932861328125 seconds to build DBF from given text.\n"
     ]
    }
   ],
   "source": [
    "times_dbf.append(kmr_time(data3)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz sprawdzę czas budowania drzewa sufiksów (użyłem danej implementacji, moja była trochę wadliwa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"A node in the suffix tree. \n",
    "    \n",
    "    suffix_node\n",
    "        the index of a node with a matching suffix, representing a suffix link.\n",
    "        -1 indicates this node has no suffix link.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.suffix_node = -1   \n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Node(suffix link: %d)\"%self.suffix_node\n",
    "\n",
    "class Edge(object):\n",
    "    \"\"\"An edge in the suffix tree.\n",
    "    \n",
    "    first_char_index\n",
    "        index of start of string part represented by this edge\n",
    "        \n",
    "    last_char_index\n",
    "        index of end of string part represented by this edge\n",
    "        \n",
    "    source_node_index\n",
    "        index of source node of edge\n",
    "    \n",
    "    dest_node_index\n",
    "        index of destination node of edge\n",
    "    \"\"\"\n",
    "    def __init__(self, first_char_index, last_char_index, source_node_index, dest_node_index):\n",
    "        self.first_char_index = first_char_index\n",
    "        self.last_char_index = last_char_index\n",
    "        self.source_node_index = source_node_index\n",
    "        self.dest_node_index = dest_node_index\n",
    "        \n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.last_char_index - self.first_char_index\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Edge(%d, %d, %d, %d)'% (self.source_node_index, self.dest_node_index \n",
    "                                        ,self.first_char_index, self.last_char_index )\n",
    "\n",
    "\n",
    "class Suffix(object):\n",
    "    \"\"\"Represents a suffix from first_char_index to last_char_index.\n",
    "    \n",
    "    source_node_index\n",
    "        index of node where this suffix starts\n",
    "    \n",
    "    first_char_index\n",
    "        index of start of suffix in string\n",
    "        \n",
    "    last_char_index\n",
    "        index of end of suffix in string\n",
    "    \"\"\"\n",
    "    def __init__(self, source_node_index, first_char_index, last_char_index):\n",
    "        self.source_node_index = source_node_index\n",
    "        self.first_char_index = first_char_index\n",
    "        self.last_char_index = last_char_index\n",
    "        \n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.last_char_index - self.first_char_index\n",
    "                \n",
    "    def explicit(self):\n",
    "        \"\"\"A suffix is explicit if it ends on a node. first_char_index\n",
    "        is set greater than last_char_index to indicate this.\n",
    "        \"\"\"\n",
    "        return self.first_char_index > self.last_char_index\n",
    "    \n",
    "    def implicit(self):\n",
    "        return self.last_char_index >= self.first_char_index\n",
    "\n",
    "        \n",
    "class SuffixTree(object):\n",
    "    \"\"\"A suffix tree for string matching. Uses Ukkonen's algorithm\n",
    "    for construction.\n",
    "    \"\"\"\n",
    "    def __init__(self, string, case_insensitive=False):\n",
    "        \"\"\"\n",
    "        string\n",
    "            the string for which to construct a suffix tree\n",
    "        \"\"\"\n",
    "        self.string = string\n",
    "        self.case_insensitive = case_insensitive\n",
    "        self.N = len(string) - 1\n",
    "        self.nodes = [Node()]\n",
    "        self.edges = {}\n",
    "        self.active = Suffix(0, 0, -1)\n",
    "        if self.case_insensitive:\n",
    "            self.string = self.string.lower()\n",
    "        for i in range(len(string)):\n",
    "            self._add_prefix(i)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\" \n",
    "        Lists edges in the suffix tree\n",
    "        \"\"\"\n",
    "        curr_index = self.N\n",
    "        s = \"\\tStart \\tEnd \\tSuf \\tFirst \\tLast \\tString\\n\"\n",
    "        values = list(self.edges.values())\n",
    "        values.sort(key=lambda x: x.source_node_index)\n",
    "        for edge in values:\n",
    "            if edge.source_node_index == -1:\n",
    "                continue\n",
    "            s += \"\\t%s \\t%s \\t%s \\t%s \\t%s \\t\"%(edge.source_node_index\n",
    "                    ,edge.dest_node_index \n",
    "                    ,self.nodes[edge.dest_node_index].suffix_node \n",
    "                    ,edge.first_char_index\n",
    "                    ,edge.last_char_index)\n",
    "                    \n",
    "            \n",
    "            top = min(curr_index, edge.last_char_index)\n",
    "            s += self.string[edge.first_char_index:top+1] + \"\\n\"\n",
    "        return s\n",
    "            \n",
    "    def _add_prefix(self, last_char_index):\n",
    "        \"\"\"The core construction method.\n",
    "        \"\"\"\n",
    "        last_parent_node = -1\n",
    "        while True:\n",
    "            parent_node = self.active.source_node_index\n",
    "            if self.active.explicit():\n",
    "                if (self.active.source_node_index, self.string[last_char_index]) in self.edges:\n",
    "                    # prefix is already in tree\n",
    "                    break\n",
    "            else:\n",
    "                e = self.edges[self.active.source_node_index, self.string[self.active.first_char_index]]\n",
    "                if self.string[e.first_char_index + self.active.length + 1] == self.string[last_char_index]:\n",
    "                    # prefix is already in tree\n",
    "                    break\n",
    "                parent_node = self._split_edge(e, self.active)\n",
    "        \n",
    "\n",
    "            self.nodes.append(Node())\n",
    "            e = Edge(last_char_index, self.N, parent_node, len(self.nodes) - 1)\n",
    "            self._insert_edge(e)\n",
    "            \n",
    "            if last_parent_node > 0:\n",
    "                self.nodes[last_parent_node].suffix_node = parent_node\n",
    "            last_parent_node = parent_node\n",
    "            \n",
    "            if self.active.source_node_index == 0:\n",
    "                self.active.first_char_index += 1\n",
    "            else:\n",
    "                self.active.source_node_index = self.nodes[self.active.source_node_index].suffix_node\n",
    "            self._canonize_suffix(self.active)\n",
    "        if last_parent_node > 0:\n",
    "            self.nodes[last_parent_node].suffix_node = parent_node\n",
    "        self.active.last_char_index += 1\n",
    "        self._canonize_suffix(self.active)\n",
    "        \n",
    "    def _insert_edge(self, edge):\n",
    "        self.edges[(edge.source_node_index, self.string[edge.first_char_index])] = edge\n",
    "        \n",
    "    def _remove_edge(self, edge):\n",
    "        self.edges.pop((edge.source_node_index, self.string[edge.first_char_index]))\n",
    "        \n",
    "    def _split_edge(self, edge, suffix):\n",
    "        self.nodes.append(Node())\n",
    "        e = Edge(edge.first_char_index, edge.first_char_index + suffix.length, suffix.source_node_index, len(self.nodes) - 1)\n",
    "        self._remove_edge(edge)\n",
    "        self._insert_edge(e)\n",
    "        self.nodes[e.dest_node_index].suffix_node = suffix.source_node_index  ### need to add node for each edge\n",
    "        edge.first_char_index += suffix.length + 1\n",
    "        edge.source_node_index = e.dest_node_index\n",
    "        self._insert_edge(edge)\n",
    "        return e.dest_node_index\n",
    "\n",
    "    def _canonize_suffix(self, suffix):\n",
    "        \"\"\"This canonizes the suffix, walking along its suffix string until it \n",
    "        is explicit or there are no more matched nodes.\n",
    "        \"\"\"\n",
    "        if not suffix.explicit():\n",
    "            e = self.edges[suffix.source_node_index, self.string[suffix.first_char_index]]\n",
    "            if e.length <= suffix.length:\n",
    "                suffix.first_char_index += e.length + 1\n",
    "                suffix.source_node_index = e.dest_node_index\n",
    "                self._canonize_suffix(suffix)\n",
    " \n",
    "\n",
    "    # Public methods\n",
    "    def find_substring(self, substring):\n",
    "        \"\"\"Returns the index of substring in string or -1 if it\n",
    "        is not found.\n",
    "        \"\"\"\n",
    "        if not substring:\n",
    "            return -1\n",
    "        if self.case_insensitive:\n",
    "            substring = substring.lower()\n",
    "        curr_node = 0\n",
    "        i = 0\n",
    "        while i < len(substring):\n",
    "            edge = self.edges.get((curr_node, substring[i]))\n",
    "            if not edge:\n",
    "                return -1\n",
    "            ln = min(edge.length + 1, len(substring) - i)\n",
    "            if substring[i:i + ln] != self.string[edge.first_char_index:edge.first_char_index + ln]:\n",
    "                return -1\n",
    "            i += edge.length + 1\n",
    "            curr_node = edge.dest_node_index\n",
    "        return edge.first_char_index - len(substring) + ln\n",
    "        \n",
    "    def has_substring(self, substring):\n",
    "        return self.find_substring(substring) != -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej czas budowania drzewa sufiksów dla kolejnych plików."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja mierząca czas budowy drzewa sufiksów\n",
    "def suffix_time(data):\n",
    "    time1 = time()\n",
    "    st = SuffixTree(data)\n",
    "    print('It took ' + str(time()-time1) + ' seconds to build Suffix Tree from given text.')\n",
    "    return time()-time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_suffix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 2.719623327255249 seconds to build Suffix Tree from given text.\n"
     ]
    }
   ],
   "source": [
    "times_suffix.append(suffix_time(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.10970735549926758 seconds to build Suffix Tree from given text.\n"
     ]
    }
   ],
   "source": [
    "times_suffix.append(suffix_time(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.007976293563842773 seconds to build Suffix Tree from given text.\n"
     ]
    }
   ],
   "source": [
    "times_suffix.append(suffix_time(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej porównanie czasów (UWAGA! Wymagana biblioteka tabulate (conda install -c conda-forge tabulate)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DBF    Suffix Tree\n",
      "----------  -------------\n",
      "25.6378        2.71962\n",
      " 0.600104      0.109707\n",
      " 0.0259304     0.00797629\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "results = [(times_dbf[0],times_suffix[0]),(times_dbf[1],times_suffix[1]),(times_dbf[2],times_suffix[2])]\n",
    "print(tabulate(results, headers=[\"DBF\", \"Suffix Tree\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wniosek:\n",
    "Wyniki nie powinny nas dziwić. Budowa drzewa sufiksów to złożoność $O(n)$ zaś budowa DBF to $O(n*logn)$ (dla Counting Sorta). Wraz ze wzrostem wielkości tekstu różnica między czasem budowy drzewa sufiksów a DBF powiększa się.  \n",
    "  \n",
    "Wykonane doświadczenie świadczy o nieliniowości algorytmu budowy DBF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Zbadać rzeczywisty rozmiar DBF, porównać z wielkością pliku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W podpunkcie tym skorzystałem z gotowej implementacji funkcji mierzącej rozmiar dowolnego obiektu w bajtach. Implementacja widoczna poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects in bytes\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for cls in obj.__class__.__mro__:\n",
    "            if '__dict__' in cls.__dict__:\n",
    "                d = cls.__dict__['__dict__']\n",
    "                if inspect.isgetsetdescriptor(d) or inspect.ismemberdescriptor(d):\n",
    "                    size += get_size(obj.__dict__, seen)\n",
    "                break\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum((get_size(v, seen) for v in obj.values()))\n",
    "        size += sum((get_size(k, seen) for k in obj.keys()))\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum((get_size(i, seen) for i in obj))\n",
    "        \n",
    "    if hasattr(obj, '__slots__'): # can have __slots__ with __dict__\n",
    "        size += sum(get_size(getattr(obj, s), seen) for s in obj.__slots__ if hasattr(obj, s))\n",
    "        \n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = kmr(data1)\n",
    "test2 = kmr(data2)\n",
    "test3 = kmr(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozmiary obiektów (DBF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609600.18359375 KB\n",
      "25655.5078125 KB\n",
      "1192.09375 KB\n"
     ]
    }
   ],
   "source": [
    "print(str(get_size(test1) / 1024) + ' KB')\n",
    "print(str(get_size(test2) / 1024) + ' KB')\n",
    "print(str(get_size(test3) / 1024) + ' KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozmiary plików:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.6953125 KB\n",
      "12.353515625 KB\n",
      "0.8837890625 KB\n"
     ]
    }
   ],
   "source": [
    "print(str(len(data1) / 1024) + ' KB')\n",
    "print(str(len(data2) / 1024) + ' KB')\n",
    "print(str(len(data3) / 1024) + ' KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile razy większy rozmiar ma obiekt od pliku?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532.663296439352\n",
      "2076.7778656126484\n",
      "1348.8441988950276\n"
     ]
    }
   ],
   "source": [
    "print((get_size(test1)) / len(data1))\n",
    "print((get_size(test2)) / len(data2))\n",
    "print((get_size(test3)) / len(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile razy dłuższy jest tekst x od tekstu 3 (najkrótszego)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272.3447513812155\n",
      "13.977900552486188\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(len(data1) / len(data3))\n",
    "print(len(data2) / len(data3))\n",
    "print(len(data3) / len(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile razy więcej zajmuje obiekt DBF dla tekstu x od obiektu DBF dla tekstu 3 (najkrótszego)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511.3693311400634\n",
      "21.521384381471677\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print((get_size(test1)) / get_size(test3))\n",
    "print((get_size(test2)) / get_size(test3))\n",
    "print((get_size(test3)) / get_size(test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wniosek\n",
    "\n",
    "Skąd wzięły się takie wyniki? Oczywistym faktem jest, że DBF będzie zajmowało więcej miejsca niż sam tekst (w końcu dla każdego $k = 2^i$ tablica Name ma długość równą długości tekstu + przechowuje inty a nie chary).  \n",
    "  \n",
    "Ilość tablic Name i Pos rośnie logarytmicznie. Długość każdej tablicy Name jest dla każdego tekstu stała i jest równa długości tekstu. Tablica Pos jednak zwiększa swoją długość (ponieważ jest więcej k-elementowych podciągów). Można podejrzewać więc, że rozmiar obiektu nie rośnie logarytmicznie do długości tekstu (albo rośnie liniowo albo logarytmicznie z dużą stałą). Przykładem tego jest fakt, że iloraz długości tekstu 1 oraz 3 jest mniejszy niż iloraz wielkości obiektu DBF dla tekstu 1 oraz 3 (długośc tekstu liniowo a iloczyn jednak jest mniejszy -> albo jest bardzo duża stała albo wielkość obiektu rośnie co najmniej liniowo).  \n",
    "  \n",
    "Przyjmujemy, że złożoność pamięciowa jest identyczna z czasową i wynosi $O(nlogn)$.  \n",
    "  \n",
    "Rozmiar $DBF$ jest zatem dużo większy od rozmiaru pliku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Porównać czas wyszukiwania wzorca przy użyciu DBF z wyszukiwaniem za pomocą KMP dla różnych długości wzorca (np. jedna litera, jedno słowo, jedno zdanie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu użyję własnej implementacji KMP (z zadania numer 1). Implementacja widoczna poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorytm KMP\n",
    "def KMPSearch(txt,pattern):\n",
    "    time1 = time()\n",
    "    S = set()\n",
    "    K = []  \n",
    "    t = -1\n",
    "    K.append(t)\n",
    "    for k in range(1, len(pattern) + 1):\n",
    "        while(t >= 0 and pattern[t] != pattern[k - 1]):\n",
    "            t = K[t]\n",
    "        t = t + 1  \n",
    "        K.append(t)\n",
    "    time1 = time()\n",
    "    m = 0  \n",
    "    for i in range(0, len(txt)):\n",
    "        while (m >= 0 and pattern[m] != txt[i]):\n",
    "            m = K[m]\n",
    "        m = m + 1  \n",
    "        if m == len(pattern):\n",
    "            S.add(i-m+1)\n",
    "            m = K[m]\n",
    "    print('It took ' + str(time()-time1) + ' seconds to find all occurences of given pattern in given text.')\n",
    "    print(\"Total found occurences: \" + str(len(S)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 30.19686770439148 seconds to build DBF from given text.\n",
      "It took 0.8457825183868408 seconds to build DBF from given text.\n",
      "It took 0.03187894821166992 seconds to build DBF from given text.\n"
     ]
    }
   ],
   "source": [
    "# przygotowanie DBF dla wersji 2 algorytmu\n",
    "dbf1 = kmr_time(data1)\n",
    "dbf2 = kmr_time(data2)\n",
    "dbf3 = kmr_time(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.08780980110168457 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 1703\n",
      "====================\n",
      "Total number of patterns found : 1703\n",
      "It took 25.14922046661377 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 1703\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data1\n",
    "pattern = 'b'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf1,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.06482672691345215 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 58\n",
      "====================\n",
      "Total number of patterns found : 58\n",
      "It took 29.972514867782593 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 58\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data1\n",
    "pattern = 'Art.'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf1,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.07679367065429688 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 1\n",
      "====================\n",
      "Total number of patterns found : 1\n",
      "It took 25.5556321144104 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 1\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data1\n",
    "pattern = 'nie wlicza się:'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf1,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0638132095336914 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 1\n",
      "====================\n",
      "Total number of patterns found : 1\n",
      "It took 51.27433180809021 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 1\n",
      "It took 0.0040247440338134766 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data1\n",
    "pattern = data1\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf1,text,pattern,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorytm KMP posiada złożoność $O(n+k)$, gdzie $n$ i $k$ to odpowiednio długość tekstu oraz wzorca. Nasz pierwszy algorytm wyszukiwania wzorca ma złożoność $O(nlogn)$ gdzie $n$ to długość tekstu. Widać więc, że dla jakiegokolwiek dłuższego tekstu (data1) różnica czasu obliczeń może być kolosalna ($\\frac{30.0}{0.07}\\approx{428}$ razy dłużej!). Gdy jednak zastosujemy drugi algorytm używający przygotowanego wcześniej $DBF$ to czas wyszukiwania jest niemal niezauważalny! Sprawdźmy jak wygląda to dla krótszych tekstów (data2 oraz data3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.002991199493408203 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 16\n",
      "====================\n",
      "Total number of patterns found : 16\n",
      "It took 0.7081522941589355 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 16\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data2\n",
    "pattern = 'ROMEO'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf2,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0030336380004882812 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 5\n",
      "====================\n",
      "Total number of patterns found : 5\n",
      "It took 0.7437288761138916 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 5\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data2\n",
    "pattern = 'KAPULET'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf2,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0029649734497070312 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 0\n",
      "====================\n",
      "Total number of patterns found : 0\n",
      "It took 0.7161164283752441 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data2\n",
    "pattern = 'NIE ZNAJDZIECIE MNIE TUTAJ NIGDZIE'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf2,text,pattern,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać, że dla krótszego tekstu iloraz jest mniejszy ($\\frac{0.70}{0.003}\\approx{233}$). Czas dla drugiego algorytmu jest nadal niezauważalny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 2\n",
      "====================\n",
      "Total number of patterns found : 2\n",
      "It took 0.027933835983276367 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 2\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data3\n",
    "pattern = 'Zaimplementować'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf3,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0009982585906982422 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 5\n",
      "====================\n",
      "Total number of patterns found : 5\n",
      "It took 0.024907350540161133 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "Total number of patterns found : 5\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data3\n",
    "pattern = 'DBF'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf3,text,pattern,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n",
      "Total found occurences: 0\n",
      "====================\n",
      "Total number of patterns found : 0\n",
      "It took 0.03191494941711426 seconds to find all occurences of given pattern in given text.\n",
      "====================\n",
      "It took 0.0 seconds to find all occurences of given pattern in given text.\n"
     ]
    }
   ],
   "source": [
    "text = data3\n",
    "pattern = 'Algorytmy tekstowe już się powoli kończą'\n",
    "KMPSearch(text,pattern)\n",
    "print('====================')\n",
    "pattern_dbf(text,pattern,False)\n",
    "print('====================')\n",
    "better_pattern_dbf(dbf3,text,pattern,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla najmniejszego tekstu iloraz jest jeszcze mniejszy ($\\frac{0.028}{0.0005}\\approx{56}$). Widać więc, że czasowo algorytmy zrównają się być może dla tekstów wielkości jednego zdania lub mniejszych (nie ma większego sensu używać takiego algorytmu).  Nadal szybkościowo wygrywa nasz drugi algorytm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wnioski  \n",
    "  \n",
    "Słownik podstawowych składowych DBF ma wiele zastosowań. Jednym z nich jest wyszukiwanie wzorca $pattern$ w tekście $text$. Z wykonanego laboratorium płyną następujące wnioski:\n",
    "  \n",
    "- algorytm wyszukiwania wzorca działający na zasadzie tworzenia $DBF$ dla $pat\\&text$ nie ma większego sensu, ponieważ $KMP$ jest zawsze szybszy oraz ma znacząco mniejsze wykorzystanie pamięciowe $O(pattern\\_length)$.  \n",
    "- algorytm wyszukiwania wzorca działający na zasadzie sprytnego wykorzystania tablic $Pos$ okazał się szybszy niż $KMP$ w każdym z zaprezentowanych przypadków. Ciągnie on niestety za sobą stworzenie słownika $DBF$, żeby móc z niego w ogóle korzystać. Dla pierwszego tekstu ($data1$) nawet przyjmując czas $0.0s$ wyszukiwania każdego wzorca musielibyśmy wykonać około $400$ wyszukań, żeby nadrobić czas przeznaczony na preprocessing $DBF$. Nasza metoda jest zatem użyteczna tylko wtedy, kiedy istnieje potrzeba wielokrotnego szukania wzorców w tekście. Oczywiście $KMP$ znowu wygrywa pod względem pamięci.  \n",
    "- algorytm tworzenia $DBF$ dla dużych tekstów potrafi osiągnąć bardzo duże rozmiary pamięciowe ($O(nlogn)$). Dla zbyt dużych tekstów może więc okazać się bezużyteczny, ponieważ zająłby zbyt dużo pamięci.  \n",
    "  \n",
    "Z powyższych wniosków płynie jeden wniosek ogólny - algorytm wyszukiwania wzorców używający $DBF$ jest użyteczny tylko wtedy, kiedy nie przejmujemy się nadto pamięcią i zamierzamy wykonywać bardzo dużo wyszukiwań. W każdym innym wypadku lepiej jest używać bazowych metod na wyszukiwanie wzorców takich jak $KMP$ czy metoda korzystająca z automatów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
